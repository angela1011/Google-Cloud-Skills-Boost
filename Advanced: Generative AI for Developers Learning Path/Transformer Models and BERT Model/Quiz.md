# Transformer Models and BERT Model: Quiz

1. BERT is a transformer model that was developed by Google in 2018. What is BERT used for?
```bash
It is used to solve many natural language processing tasks, such as question answering, text classification, and natural language inference.
```

2. What are the three different embeddings that are generated from an input sentence in a Transformer model?
```bash
Token, segment, and position embeddings
```

3. What does fine-tuning a BERT model mean?
```bash
Training the model and updating the pre-trained weights on a specific task by using labeled data
```

4. What are the encoder and decoder components of a transformer model?
```bash
The encoder ingests an input sequence and produces a sequence of hidden states. The decoder takes in the hidden states from the encoder and produces an output sequence.
```

5. What are the two sublayers of each encoder in a Transformer model?
```bash
Self-attention and feedforward
```

6. What is the name of the language modeling technique that is used in Bidirectional Encoder Representations from Transformers (BERT)?
```bash
Transformer
```

7. What is the attention mechanism?
```bash
A way of determining the importance of each word in a sentence for the translation of another sentence
```

8. What is a transformer model?
```bash
A deep learning model that uses self-attention to learn relationships between different parts of a sequence.
```

9. What kind of transformer model is BERT?
```bash
Encoder-only model
```

## Congratulation!